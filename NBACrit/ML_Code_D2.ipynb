{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f016794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937e8d0",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14540a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>game_id</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>...</th>\n",
       "      <th>over_odds</th>\n",
       "      <th>PTS_comb_actual</th>\n",
       "      <th>book_name_under</th>\n",
       "      <th>book_id_under</th>\n",
       "      <th>total1_under</th>\n",
       "      <th>under_odds</th>\n",
       "      <th>point_average_last10</th>\n",
       "      <th>point_againts_average_last10</th>\n",
       "      <th>away_point_average_last10</th>\n",
       "      <th>away_point_againts_average_last10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>11700001</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>2017</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.121</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>Pinnacle Sports</td>\n",
       "      <td>238</td>\n",
       "      <td>222.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>116.226415</td>\n",
       "      <td>104.320755</td>\n",
       "      <td>111.176893</td>\n",
       "      <td>110.534142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>11700002</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>2017</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.167</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>Bookmaker</td>\n",
       "      <td>93</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>104.435540</td>\n",
       "      <td>111.298407</td>\n",
       "      <td>105.205303</td>\n",
       "      <td>105.693687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>21700111</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>1610612745</td>\n",
       "      <td>2017</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.308</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>Pinnacle Sports</td>\n",
       "      <td>238</td>\n",
       "      <td>215.5</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>107.183333</td>\n",
       "      <td>110.787037</td>\n",
       "      <td>104.050926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>21700107</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>2017</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.371</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>5Dimes</td>\n",
       "      <td>19</td>\n",
       "      <td>209.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>105.028571</td>\n",
       "      <td>107.771429</td>\n",
       "      <td>101.091912</td>\n",
       "      <td>104.283088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>21700108</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>2017</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>Heritage</td>\n",
       "      <td>169</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>109.972222</td>\n",
       "      <td>104.277778</td>\n",
       "      <td>105.366667</td>\n",
       "      <td>115.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  GAME_DATE_EST   game_id   home_team   away_team  SEASON  PTS_home  \\\n",
       "0    2017-09-30  11700001  1610612744  1610612743    2017     102.0   \n",
       "1    2017-09-30  11700002  1610612747  1610612750    2017      99.0   \n",
       "2    2017-11-01  21700111  1610612752  1610612745    2017      97.0   \n",
       "3    2017-11-01  21700107  1610612755  1610612737    2017     119.0   \n",
       "4    2017-11-01  21700108  1610612764  1610612756    2017     116.0   \n",
       "\n",
       "   FG_PCT_home  FT_PCT_home  FG3_PCT_home  AST_home  ...  over_odds  \\\n",
       "0        0.411        0.833         0.121      17.0  ...     -110.0   \n",
       "1        0.441        0.706         0.167      27.0  ...     -110.0   \n",
       "2        0.433        0.846         0.308      23.0  ...     -107.0   \n",
       "3        0.465        0.560         0.371      36.0  ...     -104.0   \n",
       "4        0.446        0.800         0.333      20.0  ...     -105.0   \n",
       "\n",
       "   PTS_comb_actual  book_name_under  book_id_under  total1_under  under_odds  \\\n",
       "0            210.0  Pinnacle Sports            238         222.5       108.0   \n",
       "1            207.0        Bookmaker             93         216.0      -102.0   \n",
       "2            216.0  Pinnacle Sports            238         215.5      -102.0   \n",
       "3            228.0           5Dimes             19         209.0      -105.0   \n",
       "4            238.0         Heritage            169         228.0      -105.0   \n",
       "\n",
       "   point_average_last10  point_againts_average_last10  \\\n",
       "0            116.226415                    104.320755   \n",
       "1            104.435540                    111.298407   \n",
       "2             99.916667                    107.183333   \n",
       "3            105.028571                    107.771429   \n",
       "4            109.972222                    104.277778   \n",
       "\n",
       "  away_point_average_last10  away_point_againts_average_last10  \n",
       "0                111.176893                         110.534142  \n",
       "1                105.205303                         105.693687  \n",
       "2                110.787037                         104.050926  \n",
       "3                101.091912                         104.283088  \n",
       "4                105.366667                         115.866667  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file \n",
    "nba_df = pd.read_csv(\"C:/Users/tsswi/OneDrive/Desktop/DU_Classwork/Module_23_Project4/merged_df.csv\")\n",
    "\n",
    "# Review the DataFrame\n",
    "nba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cbebf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns \n",
    "nba_df.rename(columns = {'point_againts_average_last10':'point_against_average_last10', 'away_point_againts_average_last10':'away_point_against_average_last10'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c147c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-beneficial columns if applicable \n",
    "# nba_df.drop(columns=[''], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f5c179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAME_DATE_EST                         198\n",
       "game_id                              1210\n",
       "home_team                              30\n",
       "away_team                              30\n",
       "SEASON                                  1\n",
       "PTS_home                               68\n",
       "FG_PCT_home                           223\n",
       "FT_PCT_home                           174\n",
       "FG3_PCT_home                          219\n",
       "AST_home                               29\n",
       "REB_home                               37\n",
       "PTS_away                               68\n",
       "FG_PCT_away                           225\n",
       "FT_PCT_away                           181\n",
       "FG3_PCT_away                          207\n",
       "AST_away                               33\n",
       "REB_away                               42\n",
       "HOME_TEAM_WINS                          2\n",
       "book_name_over                          9\n",
       "book_id_over                            9\n",
       "total1_over                            92\n",
       "over_odds                              21\n",
       "PTS_comb_actual                       106\n",
       "book_name_under                         8\n",
       "book_id_under                           8\n",
       "total1_under                           89\n",
       "under_odds                             22\n",
       "point_average_last10                  491\n",
       "point_against_average_last10          481\n",
       "away_point_average_last10             495\n",
       "away_point_against_average_last10     484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "nba_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "583c2529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.050000    10\n",
       "101.050000     9\n",
       "102.150000     9\n",
       "105.650000     9\n",
       "102.250000     9\n",
       "              ..\n",
       "108.225000     1\n",
       "93.337500      1\n",
       "98.750000      1\n",
       "102.011111     1\n",
       "101.300000     1\n",
       "Name: point_average_last10, Length: 491, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at XXXX value counts for binning\n",
    "nba_df['point_average_last10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6952b6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1168585527.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\tsswi\\AppData\\Local\\Temp\\ipykernel_26076\\1168585527.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    last10_types_to_replace = []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of XXXX to be replaced\n",
    "# use the variable name `XXXX_types_to_replace`\n",
    "last10_types = pd.DataFrame(nba_df[['point_average_last10', 'point_against_average_last10', 'away_point_average_last10', 'away_point_against_average_last10'].value_counts().reset_index()\n",
    "\n",
    "last10_types_to_replace = []\n",
    "\n",
    "for index, row in last10_types.iterrows():\n",
    "    if row['point_average_last10','point_against_average_last10', 'away_point_average_last10', 'away_point_against_average_last10'] < 10:\n",
    "        last10_types_to_replace.append(row['index'])\n",
    "last10_types_to_replace \n",
    "\n",
    "\n",
    "# Replace in dataframe\n",
    "for last10_types in last10_types_to_replace:\n",
    "    nba_df[['point_average_last10'], ['point_against_average_last10'], ['away_point_average_last10'], ['away_point_against_average_last10']] = nba_df[['point_average_last10'], ['point_against_average_last10'], ['away_point_average_last10'], ['away_point_against_average_last10']].replace(last10_types,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "nba_df[['point_average_last10'], ['point_against_average_last10'], ['away_point_average_last10'], ['away_point_against_average_last10']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at YYYY value counts for binning\n",
    "yyyy_counts = nba_df['YYYY'].value_counts()\n",
    "yyyy_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97aebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of YYYY to be replaced\n",
    "# use the variable name `yyyy_to_replace`\n",
    "yyyy_types = pd.DataFrame(nba_df['YYYY'].value_counts()).reset_index()\n",
    "\n",
    "yyyy_to_replace = []\n",
    "\n",
    "for index, row in yyyy.iterrows():\n",
    "    if row['YYYY'] < #y:\n",
    "        yyyy_to_replace.append(row['index'])\n",
    "yyyy_to_replace \n",
    "\n",
    "# Replace in dataframe\n",
    "for yyyy in yyyy_to_replace:\n",
    "    nba_df['YYYY'] = nba_df['YYYY'].replace(yyyy,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "nba_df['YYYY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9611320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "nba_df = pd.get_dummies(nba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = nba_df['']\n",
    "X = nba_df.drop(columns='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc06b1a",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ba50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(layers.Dense(units = 100, activation = 'relu', input_dim = ))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(layers.Dense(units = 50, activation = 'elu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240725ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_modelnn = nn.fit(X_train_scaled, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788bfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413943e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
